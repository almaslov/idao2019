{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABUkAAABECAYAAAC8urRAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA4JJREFUeJzt2zFLVWEcx/H/DYmgSYoCc7Bw0KDFcyVoCaLNNxAS1FBRSw0NTYEUBA0NtRTVEoT0BtoqaAlCj0uQDlIOt6AonAKJ4PYG1Kmnp+7/8xnPs/wOHM7whafT7/cDAAAAACCrHbUHAAAAAADUJJICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApDa03WHbtv2/NQQAAAAAoKSmaTqbPd82kkZEzM33/vyaf8Tc7GjcXn1ce0Yx18bPxcaNW7VnFPFy/GzMzI7E8/nPtacUMTM7EvH9We0Z5ew5FQ++bPpPGggX9/fj8NMXtWcU8/70yVhfOF97RjHD04/iZm8w3+/66KO4tLZSe0Yx98cm4sryWO0ZxdydXIsDDydqzyjm04WV6F5tas8oZvFOG0cPXq49o4i3H+/FaPd47RnF9BZfx6sz+2rPKObEk6/RbHRrzyim3bUY3d0D/G/50cabn4P5fsd2trEw/qH2jGKmVw9F826p9oxi2iNTMbQ+mN9mRMSv4TaaqeXaM4pplyajt3ek9owiRr9t3ZFctwcAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFLr9Pv9LQ/btt36EAAAAADgP9I0TWez59tGUgAAAACAQee6PQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkNpvuTVZgasyZKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1728x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from common import *\n",
    "from io_tools import (\n",
    "    read_train, read_pub_test, read_pvt_test,\n",
    "    convert_train, convert_pub_test, convert_pvt_test,\n",
    ")\n",
    "from pipeline import (\n",
    "    split_classes, count_classes, sample,\n",
    "    cross_validate, fit_predict_save, fit_save_model\n",
    ")\n",
    "import scoring\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "color_palette = sns.color_palette('deep') + sns.color_palette('husl', 6) + sns.color_palette('bright') + sns.color_palette('pastel')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.palplot(color_palette)\n",
    "\n",
    "def ndprint(a, precision=3):\n",
    "    with np.printoptions(precision=precision, suppress=True):\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative cols\n",
    "pca_x_cols = ['PCA_X[%i]' % i for i in range(N_STATIONS)]\n",
    "pca_y_cols = ['PCA_Y[%i]' % i for i in range(N_STATIONS)]\n",
    "pca_z_cols = ['PCA_Z[%i]' % i for i in range(N_STATIONS)]\n",
    "pca_xyz_cols = pca_x_cols + pca_y_cols + pca_z_cols\n",
    "\n",
    "nerr_x_cols = ['NErr_X[%i]' % i for i in range(N_STATIONS)]\n",
    "nerr_y_cols = ['NErr_Y[%i]' % i for i in range(N_STATIONS)]\n",
    "nerr_xy_cols = nerr_x_cols + nerr_y_cols\n",
    "\n",
    "da_cols = ['DAngle[%d]' % i for i in range(1, 4)]\n",
    "is_muon_cols = ['IsMuonTight']\n",
    "prob_hit_detector_cols = ['ProbHit[%i]' % i for i in range(N_STATIONS)]\n",
    "err_cols = ['ErrMSE', 'Chi2Quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 48)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(400000, 400000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "used_cols = xyz_cols + mom_cols + hit_type_cols + dxyz_cols + exy_cols + edxy_cols\n",
    "train = read_train(used_cols, 800000)\n",
    "display(train.shape, count_classes(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformer\n",
    "\n",
    "Это по сути основная часть. Класс, который отбирает нужные столбцы, возможно что-то модифицирует или добавляет. На выходе - входные данные для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fill_na(data):\n",
    "    mask = data.isna()\n",
    "    means = data.mean(skipna=True)\n",
    "    data.fillna(means, inplace=True)\n",
    "    return mask\n",
    "\n",
    "def restore_na(data, mask):\n",
    "    data.mask(mask, other=np.NaN, inplace=True)\n",
    "    \n",
    "def get_nth_detector_coords(i):\n",
    "    return [x_cols[i], y_cols[i], z_cols[i]]\n",
    "\n",
    "def get_nth_detector_coords_pca(i):\n",
    "    return [pca_x_cols[i], pca_y_cols[i], pca_z_cols[i]]\n",
    "    \n",
    "def pca_fit(data):\n",
    "    cols = get_nth_detector_coords(0)\n",
    "    data = data[cols].copy()\n",
    "    \n",
    "    fill_na(data)\n",
    "    pca_model = PCA(n_components=3)\n",
    "    pca_model.fit(data)\n",
    "    return pca_model\n",
    "\n",
    "def pca_transform(pca_model, data, features):\n",
    "    for i in range(4):\n",
    "        cols = get_nth_detector_coords(i)\n",
    "        new_cols = get_nth_detector_coords_pca(i)\n",
    "        data_detector = data.loc[:, cols]\n",
    "        \n",
    "        mask = fill_na(data_detector)\n",
    "        transformed_data = pca_model.transform(data_detector.values)\n",
    "        restore_na(data_detector, mask)\n",
    "        return\n",
    "        \n",
    "        for j in range(3):\n",
    "            data[new_cols[j]] = transformed_data[:, j]\n",
    "\n",
    "    features += pca_coord_cols\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coses(data, features):\n",
    "    def get_layer_coords(data, i):\n",
    "        return data[[x_cols[i], y_cols[i], z_cols[i]]].values\n",
    "\n",
    "    def dot(x, y):\n",
    "        return np.sum(x * y, axis=1)\n",
    "    \n",
    "    def norm(x):\n",
    "        return np.sqrt(dot(x, x))\n",
    "\n",
    "    def get_cosine_dist(L1, L2, L1_norm, L2_norm):\n",
    "        return dot(L1, L2) / L1_norm / L2_norm\n",
    "    \n",
    "    def get_angle(cosines):\n",
    "        return np.arccos(cosines) / np.pi * 180\n",
    "    \n",
    "    layers = np.array([get_layer_coords(data, i) for i in range(4)])\n",
    "    layers[1:] -= layers[:3]\n",
    "    norms = list(map(norm, layers))\n",
    "    \n",
    "    for i in range(3):\n",
    "        cosines = get_cosine_dist(layers[i], layers[i+1], norms[i], norms[i+1])\n",
    "        angles = get_angle(cosines)\n",
    "        data[da_cols[i]] = angles\n",
    "        \n",
    "    features += da_cols        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IsMuon && IsMuonTight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_muon_tight(data, features):\n",
    "    return add_is_muon(data, features, threshold=2)\n",
    "    \n",
    "def add_is_muon(data, features, threshold=1):\n",
    "    def lt(p):\n",
    "        return data.P < p\n",
    "    def gt(p):\n",
    "        return data.P >= p\n",
    "    def M(i):\n",
    "        return data[hit_type_cols[i]] >= threshold\n",
    "    \n",
    "    lt_6k_mask = lt(6000.) & M(0) & M(1)\n",
    "    lt_10k_gt_6k_mask = gt(6000.) & lt(10000.) & M(0) & M(1) & (M(2) | M(3))\n",
    "    gt_10k_mask = gt(10000.) & M(0) & M(1) & M(2) & M(3)\n",
    "    \n",
    "    data.loc[:, is_muon_cols[0]] = 1 * (lt_6k_mask | lt_10k_gt_6k_mask | gt_10k_mask)\n",
    "    features += is_muon_cols        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probability hit detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_probability_hit_detector(data, features):\n",
    "    p = data[mom_cols[0]].values\n",
    "    \n",
    "    def prob(i):\n",
    "        alpha = (0.0260, 0.0021, 0.0015, 0.0008)\n",
    "        beta = (2040., 2387., 3320., 3903.)\n",
    "        t = (alpha[i] * (p - beta[i]))**(i+1)\n",
    "        return t / (1 + t)\n",
    "        \n",
    "    for i in range(4):\n",
    "        data.loc[:, prob_hit_detector_cols[i]] = prob(i)\n",
    "        \n",
    "    features += prob_hit_detector_cols\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mse(data, features):\n",
    "    dxy = (data.loc[:, xy_cols].values - data.loc[:, exy_cols].values) / data.loc[:, dx_cols + dy_cols].values / 2.\n",
    "    D = np.mean(dxy**2, axis=1)\n",
    "    \n",
    "    data.loc[:, err_cols[0]] = D\n",
    "    features += [err_cols[0]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normed_err(data, features):\n",
    "    dxy = data.loc[:, xy_cols].values - data.loc[:, exy_cols].values\n",
    "    normed_errors = dxy / np.sqrt(data.loc[:, edxy_cols].values)\n",
    "    \n",
    "    for i in range(4):\n",
    "        data.loc[:, nerr_x_cols[i]] = normed_errors[:, i]\n",
    "        data.loc[:, nerr_y_cols[i]] = normed_errors[:, i + 4]\n",
    "    \n",
    "    features += nerr_xy_cols\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>scr</th>\n",
       "      <th>th</th>\n",
       "      <th>dTh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.683550</td>\n",
       "      <td>0.628798</td>\n",
       "      <td>0.897744</td>\n",
       "      <td>0.739428</td>\n",
       "      <td>0.711575</td>\n",
       "      <td>0.448912</td>\n",
       "      <td>0.058076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012158</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.614910</td>\n",
       "      <td>0.885089</td>\n",
       "      <td>0.734489</td>\n",
       "      <td>0.703814</td>\n",
       "      <td>0.421364</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.678142</td>\n",
       "      <td>0.622858</td>\n",
       "      <td>0.890714</td>\n",
       "      <td>0.737489</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.438992</td>\n",
       "      <td>0.057201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.685892</td>\n",
       "      <td>0.630807</td>\n",
       "      <td>0.896340</td>\n",
       "      <td>0.740488</td>\n",
       "      <td>0.708187</td>\n",
       "      <td>0.456620</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.690130</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.904072</td>\n",
       "      <td>0.741898</td>\n",
       "      <td>0.715455</td>\n",
       "      <td>0.462686</td>\n",
       "      <td>0.059512</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.694367</td>\n",
       "      <td>0.640678</td>\n",
       "      <td>0.911804</td>\n",
       "      <td>0.743307</td>\n",
       "      <td>0.722724</td>\n",
       "      <td>0.468752</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc      prec       rec        f1   roc_auc       scr        th  \\\n",
       "count  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000   \n",
       "mean   0.683550  0.628798  0.897744  0.739428  0.711575  0.448912  0.058076   \n",
       "std    0.012158  0.013001  0.013413  0.004504  0.009900  0.024617  0.002508   \n",
       "min    0.670391  0.614910  0.885089  0.734489  0.703814  0.421364  0.055203   \n",
       "25%    0.678142  0.622858  0.890714  0.737489  0.706000  0.438992  0.057201   \n",
       "50%    0.685892  0.630807  0.896340  0.740488  0.708187  0.456620  0.059199   \n",
       "75%    0.690130  0.635742  0.904072  0.741898  0.715455  0.462686  0.059512   \n",
       "max    0.694367  0.640678  0.911804  0.743307  0.722724  0.468752  0.059825   \n",
       "\n",
       "       dTh  \n",
       "count  3.0  \n",
       "mean   0.0  \n",
       "std    0.0  \n",
       "min    0.0  \n",
       "25%    0.0  \n",
       "50%    0.0  \n",
       "75%    0.0  \n",
       "max    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataTransformer(TransformerMixin):\n",
    "    def __init__(self, *featurizers):\n",
    "        self.featurizers = featurizers\n",
    "    \n",
    "    def fit(self, data, y=None):\n",
    "#         self.pca_model = pca_fit(data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        data = data.copy()\n",
    "        features = [] + xyz_cols + mom_cols + hit_type_cols + dxyz_cols + exy_cols + edxy_cols\n",
    "\n",
    "#         pca_transform(self.pca_model, data, features)\n",
    "#         add_is_muon(data, features)\n",
    "#         add_is_muon_tight(data, features)\n",
    "#         add_probability_hit_detector(data, features)\n",
    "#         add_coses(data, features)\n",
    "#         add_mse(data, features)\n",
    "#         add_normed_err(data, features)\n",
    "                \n",
    "        if features:\n",
    "            data = data.loc[:, features]\n",
    "        else:\n",
    "            data = data.drop(train_cols, axis=1)\n",
    "        return data\n",
    "\n",
    "df_scores = cross_validate(train, n_estimators=60, n_splits=3, n_rows=40000, transformer_cls=DataTransformer)\n",
    "display(df_scores.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in arccos\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in arccos\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in arccos\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in arccos\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in arccos\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>scr</th>\n",
       "      <th>th</th>\n",
       "      <th>dTh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.791887</td>\n",
       "      <td>0.802323</td>\n",
       "      <td>0.879413</td>\n",
       "      <td>0.839101</td>\n",
       "      <td>0.803445</td>\n",
       "      <td>0.750368</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>6.824732e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>1.526056e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.791505</td>\n",
       "      <td>0.801749</td>\n",
       "      <td>0.878686</td>\n",
       "      <td>0.838887</td>\n",
       "      <td>0.802229</td>\n",
       "      <td>0.735307</td>\n",
       "      <td>0.095154</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.791600</td>\n",
       "      <td>0.802040</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.838899</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.748356</td>\n",
       "      <td>0.095548</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.791795</td>\n",
       "      <td>0.802279</td>\n",
       "      <td>0.879618</td>\n",
       "      <td>0.838930</td>\n",
       "      <td>0.803601</td>\n",
       "      <td>0.751873</td>\n",
       "      <td>0.095797</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.791945</td>\n",
       "      <td>0.802616</td>\n",
       "      <td>0.879634</td>\n",
       "      <td>0.839170</td>\n",
       "      <td>0.803913</td>\n",
       "      <td>0.757279</td>\n",
       "      <td>0.095908</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.792590</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.879820</td>\n",
       "      <td>0.839620</td>\n",
       "      <td>0.803995</td>\n",
       "      <td>0.759022</td>\n",
       "      <td>0.097193</td>\n",
       "      <td>3.412366e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc      prec       rec        f1   roc_auc       scr        th  \\\n",
       "count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
       "mean   0.791887  0.802323  0.879413  0.839101  0.803445  0.750368  0.095920   \n",
       "std    0.000428  0.000466  0.000446  0.000312  0.000712  0.009431  0.000768   \n",
       "min    0.791505  0.801749  0.878686  0.838887  0.802229  0.735307  0.095154   \n",
       "25%    0.791600  0.802040  0.879310  0.838899  0.803487  0.748356  0.095548   \n",
       "50%    0.791795  0.802279  0.879618  0.838930  0.803601  0.751873  0.095797   \n",
       "75%    0.791945  0.802616  0.879634  0.839170  0.803913  0.757279  0.095908   \n",
       "max    0.792590  0.802933  0.879820  0.839620  0.803995  0.759022  0.097193   \n",
       "\n",
       "                dTh  \n",
       "count  5.000000e+00  \n",
       "mean   6.824732e-07  \n",
       "std    1.526056e-06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    3.412366e-06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_scores = cross_validate(train, n_splits=5, n_rows=1000000)\n",
    "display(df_scores.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_pub_test(used_cols, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in arccos\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_predict_save(get_head_w_proportions(train, 1000000, None), test, \"out/07_full_0_label_1000k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_predict_save(get_head_w_proportions(train, 1300000, .3), test, \"out/06_x_dx_ex_edx_mom_hit_phit_da_mse_nerr_30_1300k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_predict_save(get_head_w_proportions(train, 1700000, .5), test, \"out/06_x_dx_ex_edx_mom_hit_phit_da_mse_nerr_50_1700k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_predict_save(get_samples_w_proptions(train, 100000, .5), test, \"out/04_prop_80_20_100_800.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_predict_save(get_samples(train, 100000), test, \"out/03_baseline_head_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_save_model(get_head_w_proportions(train, 100000, .5), \"models/06_x_dx_ex_edx_mom_hit_da_mse_50_100k.xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([[1.0, np.NaN], [np.NaN, np.NaN], [2.0, 3.1]], columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_backup = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('data/train_part_1_v2.csv.gz', na_values=['-9999.0', '255'], index_col=utils.ID_COLUMN)\n",
    "# train = pd.read_csv('data/train_part_2_v2.csv.gz', nrows=10000, na_values=['-9999.0', '255'])\n",
    "# train = pd.concat([train_0, train_1], axis=0, ignore_index=True)\n",
    "\n",
    "label0 = train.loc[train.label==0, :]\n",
    "label0.to_csv('data/train_pub_L0_p1.csv.gz', compression='gzip')\n",
    "\n",
    "label1 = train.loc[train.label==1, :]\n",
    "label1.to_csv('data/train_pub_L1_p1.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label0.to_pickle('data/train_pub_L0_p1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label1.to_pickle('data/train_pub_L1_p1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210403, 79), (2512449, 79))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label0.shape, label1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_csv('data/train_part_2_v2.csv.gz', na_values=['-9999.0', '255'], index_col=utils.ID_COLUMN)\n",
    "# train = pd.read_csv('data/train_part_2_v2.csv.gz', nrows=10000, na_values=['-9999.0', '255'])\n",
    "# train = pd.concat([train_0, train_1], axis=0, ignore_index=True)\n",
    "\n",
    "label0 = train.loc[train.label==0, :]\n",
    "label0.to_csv('data/train_pub_L0_p2.csv.gz', compression='gzip')\n",
    "\n",
    "label1 = train.loc[train.label==1, :]\n",
    "label1.to_csv('data/train_pub_L1_p2.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 79) (736, 79)\n",
      "Wall time: 702 ms\n"
     ]
    }
   ],
   "source": [
    "# label0_ = pd.read_csv('data/train_pub_L0_p1.csv', nrows=10000, na_values=['-9999.0', '255'], index_col=utils.ID_COLUMN)\n",
    "\n",
    "# print(label0.shape, label0_.shape)\n",
    "\n",
    "# for c in label0.columns:\n",
    "#     lc0 = label0.loc[:, c]\n",
    "#     if not np.issubdtype(lc0.dtype, np.number):\n",
    "#         continue\n",
    "#     lc0_ = label0_.loc[:, c]\n",
    "#     mask = (lc0 - lc0_).abs() > 1e-10\n",
    "#     if mask.sum() > 0 :\n",
    "#         display(lc0[mask] - lc0_[mask])\n",
    "        \n",
    "\n",
    "# for c in label0.columns:\n",
    "#     lc0 = label0.loc[:, c]\n",
    "#     if np.issubdtype(lc0.dtype, np.number):\n",
    "#         continue\n",
    "#     lc0_ = label0_.loc[:, c]\n",
    "#     mask = (lc0 != lc0_) & (lc0 == lc0) & (lc0_ == lc0_)\n",
    "#     for i in range(mask.sum()):\n",
    "#         s0 = ''.join(lc0.iloc[mask].iloc[i].split())\n",
    "#         s1 = ''.join(lc0_.iloc[mask].iloc[i].split())\n",
    "#         if s0 == s1:\n",
    "#             continue\n",
    "        \n",
    "#         print(lc0.iloc[0])\n",
    "#         print(lc0_.iloc[0])\n",
    "#         for i,s in enumerate(difflib.ndiff(lc0.iloc[0], lc0_.iloc[0])):\n",
    "#             if s[0]==' ': continue\n",
    "#             elif s[0]=='-':\n",
    "#                 print(u'Delete \"{}\" `{}` from position {}'.format(s[-1], ord(s[-1]),i))\n",
    "#             elif s[0]=='+':\n",
    "#                 print(u'Add \"{}\" `{}` to position {}'.format(s[-1],ord(s[-1]),i))    \n",
    "#         print()  \n",
    "\n",
    "# display(label0[mask].head(10))\n",
    "# display(label0_[mask].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
